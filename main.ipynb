{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699e9b06-b66b-4b3c-a801-5a7e458f728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bb1d80e-0219-427c-b4f4-e3fb0cd57c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import DatasetDict\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "from src.configuration.set_up_config_device import (\n",
    "    get_allowed_cpu_count,\n",
    "    set_up_config_device,\n",
    "    set_up_device,\n",
    ")\n",
    "from src.data_processing.loading import load_iob_data\n",
    "from src.data_processing.tokenization import create_tokenized_dataset\n",
    "from src.data_processing.descriptive_statistics import descriptive_statistics\n",
    "from src.model.transformer import (\n",
    "    Transformer,\n",
    "    TransformerForNER,\n",
    ")\n",
    "from src.model.train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9796c8b-522c-4c5b-b797-74460f40cb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:08:41 - INFO - Using cpu device\n",
      "2025-04-11 13:08:41 - INFO - Using 128 CPUs\n",
      "2025-04-11 13:08:41 - INFO - torch set up to use 64 processes\n"
     ]
    }
   ],
   "source": [
    "device = set_up_device()\n",
    "cpu_count = get_allowed_cpu_count()\n",
    "n_process = set_up_config_device(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c46abe-6b9b-49a3-a45c-f4f5e00dad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c985dc-b1db-41ae-9aaa-38c63d64f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-5\n",
    "NB_EPOCHS = 5\n",
    "LOG_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698bd6ab-cc15-4f9d-9afe-ad633325e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMETERS = {\n",
    "    \"pad_idx\": 0,\n",
    "    \"voc_size\": tokenizer.vocab_size,\n",
    "    \"hidden_size\": 256,\n",
    "    \"n_head\": 4,\n",
    "    \"max_len\": 512,\n",
    "    \"dec_max_len\": 128,\n",
    "    \"ffn_hidden\": 512,\n",
    "    \"n_layers\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814b963-01eb-481a-b349-7bb7599c8742",
   "metadata": {},
   "source": [
    "# **LOAD & PROCESS DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a1a5bf-d5b3-4132-8791-ec142feed72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = load_iob_data(\"data/raw/train-nl.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd68a0a-fb75-413c-8d46-6a9f05eacf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2199/2199 [00:02<00:00, 1092.83 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 3/3 [00:00<00:00,  5.57ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset saved at: data/tokenized/tokenized_dataset.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = create_tokenized_dataset(\n",
    "    sentences, labels, save_path=\"data/tokenized/tokenized_dataset.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81806291-39df-4a87-8ab8-3c0a8d1fedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Split test into validation/test\n",
    "val_test = train_test[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Recombine into final DatasetDict\n",
    "split_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"validation\": val_test[\"train\"],\n",
    "        \"test\": val_test[\"test\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a659d555-9711-44f8-8400-1d3d69d1081c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1759\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 220\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 220\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71b6dc3-2565-4a38-a4be-7557dbb70506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, padding=True, max_length=512, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "train_dataset = split_dataset[\"train\"].remove_columns([\"tokens\", \"ner_tags\"])\n",
    "val_dataset = split_dataset[\"validation\"].remove_columns([\"tokens\", \"ner_tags\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f3d08-c790-4bae-aadd-ba6057c158d9",
   "metadata": {},
   "source": [
    "# **DESCRIPTIVE STATISTICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79292ce6-976d-457d-b7a4-187c5a4c3add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Summary:\n",
      "   num_sentences  min_length  mean_length  max_length\n",
      "0           2199           1   227.498863         703\n",
      "\n",
      "IOB Tag Statistics (per sentence):\n",
      "                                 min        mean    max\n",
      "B-Organization                   0.0    0.483856    7.0\n",
      "B-Organization,B-Place           0.0    0.001364    1.0\n",
      "B-Organization,I-Person          0.0    0.001819    2.0\n",
      "B-Organization,I-Place           0.0    0.016371    2.0\n",
      "B-Person                         0.0    5.238290   47.0\n",
      "B-Person,B-Place                 0.0    0.000910    1.0\n",
      "B-Person,I-Place                 0.0    0.011369    1.0\n",
      "B-Place                          0.0    1.858572   12.0\n",
      "I-Organization                   0.0    1.435198   25.0\n",
      "I-Organization,B-Place           0.0    0.135516    3.0\n",
      "I-Organization,I-Person          0.0    0.005912    7.0\n",
      "I-Organization,I-Person,B-Place  0.0    0.000910    1.0\n",
      "I-Organization,I-Person,I-Place  0.0    0.000910    1.0\n",
      "I-Organization,I-Place           0.0    0.073215    5.0\n",
      "I-Person                         0.0    9.984538   80.0\n",
      "I-Person,B-Place                 0.0    0.075944   16.0\n",
      "I-Person,I-Place                 0.0    0.035016    5.0\n",
      "I-Place                          0.0    2.480218  104.0\n",
      "O                                0.0  205.658936  633.0\n"
     ]
    }
   ],
   "source": [
    "descriptive_statistics(sentences, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca51ab-4bc6-40bf-b60b-2465aa29af49",
   "metadata": {},
   "source": [
    "# **DEFINE & TRAIN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3276bd-8772-49a8-9b84-91d382ef9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\n",
    "    label for example in split_dataset[\"train\"] for label in example[\"ner_tags\"]\n",
    "]\n",
    "unique_ids = sorted(set(all_labels))\n",
    "label2id = {label: label for label in unique_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e236b-3b81-4c82-ad10-0df7cabb6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Transformer(**MODEL_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27050561-b2bc-447a-ad93-e384b593a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerForNER(base_model, hidden_size=256, num_labels=len(label2id)).to(\n",
    "    device\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2a2f6-4277-4514-a5ab-40d89f8eb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=NB_EPOCHS,\n",
    "    log_steps=LOG_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4457c6-7db9-4dae-9aa4-118de7e090e7",
   "metadata": {},
   "source": [
    "# **EVALUATE RESULTS**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
