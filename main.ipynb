{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1d80e-0219-427c-b4f4-e3fb0cd57c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import DatasetDict\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter\n",
    "\n",
    "from src.configuration.set_up_config_device import (\n",
    "    get_allowed_cpu_count,\n",
    "    set_up_config_device,\n",
    "    set_up_device,\n",
    ")\n",
    "from src.data_processing.loading import load_iob_data\n",
    "from src.data_processing.tokenization import create_tokenized_dataset\n",
    "from src.model.transformer import (\n",
    "    Transformer,\n",
    "    TransformerForNER,\n",
    ")\n",
    "from src.model.train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9796c8b-522c-4c5b-b797-74460f40cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_up_device()\n",
    "cpu_count = get_allowed_cpu_count()\n",
    "n_process = set_up_config_device(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c46abe-6b9b-49a3-a45c-f4f5e00dad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c985dc-b1db-41ae-9aaa-38c63d64f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-5\n",
    "NB_EPOCHS = 5\n",
    "LOG_STEPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bd6ab-cc15-4f9d-9afe-ad633325e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PARAMETERS = {\n",
    "    \"pad_idx\":0,\n",
    "    \"voc_size\"=tokenizer.vocab_size,\n",
    "    \"hidden_size\"=256,\n",
    "    \"n_head\"=4,\n",
    "    \"max_len\"=512,\n",
    "    \"dec_max_len\"=128,\n",
    "    \"ffn_hidden\"=512,\n",
    "    \"n_layers\"=4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814b963-01eb-481a-b349-7bb7599c8742",
   "metadata": {},
   "source": [
    "# **LOAD & PROCESS DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1a5bf-d5b3-4132-8791-ec142feed72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = load_iob_data(\"data/raw/train-nl.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd68a0a-fb75-413c-8d46-6a9f05eacf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = create_tokenized_dataset(\n",
    "    sentences, labels, save_path=\"data/tokenized/tokenized_dataset.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81806291-39df-4a87-8ab8-3c0a8d1fedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Split test into validation/test\n",
    "val_test = train_test[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Recombine into final DatasetDict\n",
    "split_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"validation\": val_test[\"train\"],\n",
    "        \"test\": val_test[\"test\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659d555-9711-44f8-8400-1d3d69d1081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b6dc3-2565-4a38-a4be-7557dbb70506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer, padding=True, max_length=512, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "train_dataset = split_dataset[\"train\"].remove_columns([\"tokens\", \"ner_tags\"])\n",
    "val_dataset = split_dataset[\"validation\"].remove_columns([\"tokens\", \"ner_tags\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f3d08-c790-4bae-aadd-ba6057c158d9",
   "metadata": {},
   "source": [
    "# **DESCRIPTIVE STATISTICS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca51ab-4bc6-40bf-b60b-2465aa29af49",
   "metadata": {},
   "source": [
    "# **DEFINE & TRAIN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3276bd-8772-49a8-9b84-91d382ef9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\n",
    "    label for example in split_dataset[\"train\"] for label in example[\"ner_tags\"]\n",
    "]\n",
    "unique_ids = sorted(set(all_labels))\n",
    "label2id = {label: label for label in unique_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e236b-3b81-4c82-ad10-0df7cabb6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Transformer(**MODEL_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27050561-b2bc-447a-ad93-e384b593a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerForNER(base_model, hidden_size=256, num_labels=len(label2id)).to(\n",
    "    device\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea2a2f6-4277-4514-a5ab-40d89f8eb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=NB_EPOCHS,\n",
    "    log_steps=LOG_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4457c6-7db9-4dae-9aa4-118de7e090e7",
   "metadata": {},
   "source": [
    "# **EVALUATE RESULTS**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
